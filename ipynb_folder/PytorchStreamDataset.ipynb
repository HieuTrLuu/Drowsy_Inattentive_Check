{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "PytorchStreamDataset.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZqrNVX_f5RD8",
        "outputId": "0ed8f714-c7ef-46ff-f0ea-30ce880c04df"
      },
      "source": [
        "!pip install av"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting av\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/41/b7/4b1095af7f8e87c0f54fc0a3de9472d09583eaf2e904a60f0817819fff11/av-8.0.3-cp36-cp36m-manylinux2010_x86_64.whl (37.2MB)\n",
            "\u001b[K     |████████████████████████████████| 37.2MB 1.2MB/s \n",
            "\u001b[?25hInstalling collected packages: av\n",
            "Successfully installed av-8.0.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBECvUJc4w5T",
        "outputId": "f94b7408-6459-4210-8cf1-e99fa00f8cea"
      },
      "source": [
        "import torchvision\r\n",
        "import cv2\r\n",
        "video_path = '/content/test_video2.mp4'\r\n",
        "_time = torchvision.io.read_video_timestamps(video_path)\r\n",
        "time_stamps = _time[0]\r\n",
        "frames = torchvision.io.read_video(video_path, start_pts=time_stamps[10], end_pts=time_stamps[100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/io/video.py:117: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  + \"follow-up version. Please use pts_unit 'sec'.\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qy2iDyhC6mmP",
        "outputId": "dc5f54e6-20df-4cfd-b780-6af2d1f0cb82"
      },
      "source": [
        "%%time\r\n",
        "frames = torchvision.io.read_video(video_path, start_pts=time_stamps[199])\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torchvision/io/video.py:117: UserWarning: The pts_unit 'pts' gives wrong results and will be removed in a follow-up version. Please use pts_unit 'sec'.\n",
            "  + \"follow-up version. Please use pts_unit 'sec'.\"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 380 ms, sys: 7.96 ms, total: 388 ms\n",
            "Wall time: 408 ms\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uYj0JQoR51Fl",
        "outputId": "64a7cb16-75b8-4075-d00a-35abce643e5c"
      },
      "source": [
        "%%time\r\n",
        "import cv2\r\n",
        "vidcap = cv2.VideoCapture(video_path)\r\n",
        "success,image = vidcap.read()\r\n",
        "count = 0\r\n",
        "l = []\r\n",
        "while success:\r\n",
        "  success,image = vidcap.read()\r\n",
        "  l.append(image)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2.88 s, sys: 138 ms, total: 3.02 s\n",
            "Wall time: 1.72 s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D1MNr_9n6jO-"
      },
      "source": [
        "# reader = torchvision.io.VideoReader(video_path, \"video\")\r\n",
        "# reader.seek(2.0)\r\n",
        "# frame = next(reader)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yH0dF6GN7xHO"
      },
      "source": [
        "import torchvision\r\n",
        "import torch\r\n",
        "import math\r\n",
        "from torch.utils.data import DataLoader\r\n",
        "# from torch.utils.data import IterableDataset\r\n",
        "\r\n",
        "\r\n",
        "import random\r\n",
        "from itertools import chain, cycle\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vkySKQCNF_a6"
      },
      "source": [
        "class IterDataset(torch.utils.data.IterableDataset):\r\n",
        "    def __init__(self, data):\r\n",
        "        super(MyIterableDataset).__init__()\r\n",
        "        #  assert end > start, \"this example code only works with end >= start\"\r\n",
        "        self.data_list = data_list\r\n",
        "        self.batch_size = batch_size\r\n",
        "\r\n",
        "    def shuffle_data_list(self):\r\n",
        "        return random.sample(self.data_list, len(self.data_list))\r\n",
        "\r\n",
        "\r\n",
        "    def process_data(self, data_list, batch_size):\r\n",
        "        for x in data:\r\n",
        "            yield x\r\n",
        "        \r\n",
        "    def get_stream(self, data_list):\r\n",
        "        return chain.from_iterable(map(self.process_data, cycle(data_list)))\r\n",
        "\r\n",
        "    def get_streams(self):\r\n",
        "        pass\r\n",
        "\r\n",
        "    def __iter__(self):\r\n",
        "        return iter(self.data)\r\n",
        "\r\n",
        "def worker_init_fn(worker_id):\r\n",
        "    worker_info = torch.utils.data.get_worker_info()\r\n",
        "    dataset = worker_info.dataset  # the dataset copy in this worker process\r\n",
        "    overall_start = dataset.start\r\n",
        "    overall_end = dataset.end\r\n",
        "    # configure the dataset to only process the split workload\r\n",
        "    per_worker = int(math.ceil((overall_end - overall_start) / float(worker_info.num_workers)))\r\n",
        "    worker_id = worker_info.id\r\n",
        "    dataset.start = overall_start + worker_id * per_worker\r\n",
        "    dataset.end = min(dataset.start + per_worker, overall_end)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}