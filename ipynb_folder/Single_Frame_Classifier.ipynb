{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T15:48:55.241505Z",
     "iopub.status.busy": "2021-02-23T15:48:55.240700Z",
     "iopub.status.idle": "2021-02-23T15:49:15.988723Z",
     "shell.execute_reply": "2021-02-23T15:49:15.987901Z"
    },
    "papermill": {
     "duration": 20.78011,
     "end_time": "2021-02-23T15:49:15.988944",
     "exception": false,
     "start_time": "2021-02-23T15:48:55.208834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "\r\n",
      "\r\n",
      "pkg-config is already the newest version (0.29.1-0ubuntu2).\r\n",
      "python-dev is already the newest version (2.7.15~rc1-1).\r\n",
      "python-dev set to manually installed.\r\n",
      "0 upgraded, 0 newly installed, 0 to remove and 21 not upgraded.\r\n",
      "\r\n",
      "\r\n",
      "\r\n",
      "The following additional packages will be installed:\r\n",
      "  libavresample-dev libpostproc-dev\r\n",
      "The following NEW packages will be installed:\r\n",
      "  libavcodec-dev libavdevice-dev libavfilter-dev libavformat-dev\r\n",
      "  libavresample-dev libavutil-dev libpostproc-dev libswresample-dev\r\n",
      "  libswscale-dev\r\n",
      "0 upgraded, 9 newly installed, 0 to remove and 21 not upgraded.\r\n",
      "Need to get 7956 kB of archives.\r\n",
      "After this operation, 33.5 MB of additional disk space will be used.\r\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavutil-dev amd64 7:3.4.8-0ubuntu0.2 [294 kB]\r\n",
      "Get:2 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libswresample-dev amd64 7:3.4.8-0ubuntu0.2 [68.7 kB]\r\n",
      "Get:3 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavcodec-dev amd64 7:3.4.8-0ubuntu0.2 [5079 kB]\r\n",
      "Get:4 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavformat-dev amd64 7:3.4.8-0ubuntu0.2 [1132 kB]\r\n",
      "Get:5 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavresample-dev amd64 7:3.4.8-0ubuntu0.2 [62.0 kB]\r\n",
      "Get:6 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libpostproc-dev amd64 7:3.4.8-0ubuntu0.2 [51.0 kB]\r\n",
      "Get:7 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libswscale-dev amd64 7:3.4.8-0ubuntu0.2 [166 kB]\r\n",
      "Get:8 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavfilter-dev amd64 7:3.4.8-0ubuntu0.2 [1016 kB]\r\n",
      "Get:9 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 libavdevice-dev amd64 7:3.4.8-0ubuntu0.2 [87.2 kB]\r\n",
      "Fetched 7956 kB in 1s (6758 kB/s)\r\n",
      "debconf: delaying package configuration, since apt-utils is not installed\r\n",
      "Selecting previously unselected package libavutil-dev:amd64.\r\n",
      "(Reading database ... 116896 files and directories currently installed.)\r\n",
      "Preparing to unpack .../0-libavutil-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libavutil-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libswresample-dev:amd64.\r\n",
      "Preparing to unpack .../1-libswresample-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libswresample-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libavcodec-dev:amd64.\r\n",
      "Preparing to unpack .../2-libavcodec-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libavcodec-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libavformat-dev:amd64.\r\n",
      "Preparing to unpack .../3-libavformat-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libavformat-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libavresample-dev:amd64.\r\n",
      "Preparing to unpack .../4-libavresample-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libavresample-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libpostproc-dev:amd64.\r\n",
      "Preparing to unpack .../5-libpostproc-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libpostproc-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libswscale-dev:amd64.\r\n",
      "Preparing to unpack .../6-libswscale-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libswscale-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libavfilter-dev:amd64.\r\n",
      "Preparing to unpack .../7-libavfilter-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libavfilter-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Selecting previously unselected package libavdevice-dev:amd64.\r\n",
      "Preparing to unpack .../8-libavdevice-dev_7%3a3.4.8-0ubuntu0.2_amd64.deb ...\r\n",
      "Unpacking libavdevice-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Setting up libavutil-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Setting up libavresample-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Setting up libpostproc-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Setting up libswscale-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Setting up libswresample-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Setting up libavcodec-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Setting up libavformat-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Setting up libavfilter-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Setting up libavdevice-dev:amd64 (7:3.4.8-0ubuntu0.2) ...\r\n",
      "Collecting av\r\n",
      "  Downloading av-8.0.3-cp37-cp37m-manylinux2010_x86_64.whl (37.2 MB)\r\n",
      "\u001b[K     |████████████████████████████████| 37.2 MB 150 kB/s \r\n",
      "\u001b[?25hInstalling collected packages: av\r\n",
      "Successfully installed av-8.0.3\r\n",
      "\u001b[33mWARNING: You are using pip version 21.0; however, version 21.0.1 is available.\r\n",
      "You should consider upgrading via the '/opt/conda/bin/python3.7 -m pip install --upgrade pip' command.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# install torchvision for kaggle\n",
    "!apt-get install -y python-dev pkg-config\n",
    "!apt-get install -y libavformat-dev libavcodec-dev libavdevice-dev libavutil-dev libswscale-dev libswresample-dev libavfilter-dev\n",
    "!pip install av"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-23T15:49:16.124823Z",
     "iopub.status.busy": "2021-02-23T15:49:16.124089Z",
     "iopub.status.idle": "2021-02-23T15:49:17.979266Z",
     "shell.execute_reply": "2021-02-23T15:49:17.977750Z"
    },
    "papermill": {
     "duration": 1.925262,
     "end_time": "2021-02-23T15:49:17.979425",
     "exception": false,
     "start_time": "2021-02-23T15:49:16.054163",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/drowsiness-batch-dataset-fold2-1/Fold_2_1.csv\n",
      "/kaggle/input/drowsiness-batch-dataset-fold2-1/__results__.html\n",
      "/kaggle/input/drowsiness-batch-dataset-fold2-1/__notebook__.ipynb\n",
      "/kaggle/input/drowsiness-batch-dataset-fold2-1/__output__.json\n",
      "/kaggle/input/drowsiness-batch-dataset-fold2-1/custom.css\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/__results__.html\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/__notebook__.ipynb\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/__output__.json\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/custom.css\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/35/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/35/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/35/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/36/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/36/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/36/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/32/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/32/10_1.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/32/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/32/10_2.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/31/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/31/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/31/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/34/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/34/0.mov\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/34/5.mov\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/33/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/33/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-2/Fold3_part2/33/0.mp4\n",
      "/kaggle/input/fork-of-drowsiness-batch-dataset-fold2-2/__results__.html\n",
      "/kaggle/input/fork-of-drowsiness-batch-dataset-fold2-2/Fold_2_2.csv\n",
      "/kaggle/input/fork-of-drowsiness-batch-dataset-fold2-2/__notebook__.ipynb\n",
      "/kaggle/input/fork-of-drowsiness-batch-dataset-fold2-2/__output__.json\n",
      "/kaggle/input/fork-of-drowsiness-batch-dataset-fold2-2/custom.css\n",
      "/kaggle/input/drowsiness-batch-dataset-fold1-2/__results__.html\n",
      "/kaggle/input/drowsiness-batch-dataset-fold1-2/Fold_1_2.csv\n",
      "/kaggle/input/drowsiness-batch-dataset-fold1-2/__notebook__.ipynb\n",
      "/kaggle/input/drowsiness-batch-dataset-fold1-2/__output__.json\n",
      "/kaggle/input/drowsiness-batch-dataset-fold1-2/custom.css\n",
      "/kaggle/input/drowsiness-batch-dataset-fold1-1/Fold_1_1.csv\n",
      "/kaggle/input/drowsiness-batch-dataset-fold1-1/__results__.html\n",
      "/kaggle/input/drowsiness-batch-dataset-fold1-1/__notebook__.ipynb\n",
      "/kaggle/input/drowsiness-batch-dataset-fold1-1/__output__.json\n",
      "/kaggle/input/drowsiness-batch-dataset-fold1-1/custom.css\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/__results__.html\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/__notebook__.ipynb\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/__output__.json\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/custom.css\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/07/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/07/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/07/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/10/10.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/10/0.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/10/5.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/12/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/12/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/12/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/08/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/08/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/08/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/09/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/09/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/09/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/11/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/11/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-2/Fold1_part2/11/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/__results__.html\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/__notebook__.ipynb\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/__output__.json\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/custom.css\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/19/10.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/19/0.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/19/5.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/22/10.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/22/0.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/22/5.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/23/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/23/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/23/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/20/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/20/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/20/5.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/21/10.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/21/0.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/21/5.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/24/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/24/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-2/Fold2_part2/24/0.mp4\n",
      "/kaggle/input/drowsiness-batch-dataset-fold3-1/__results__.html\n",
      "/kaggle/input/drowsiness-batch-dataset-fold3-1/Fold_3_1.csv\n",
      "/kaggle/input/drowsiness-batch-dataset-fold3-1/__notebook__.ipynb\n",
      "/kaggle/input/drowsiness-batch-dataset-fold3-1/__output__.json\n",
      "/kaggle/input/drowsiness-batch-dataset-fold3-1/custom.css\n",
      "/kaggle/input/meta-df-pickle/meta_df.pkl\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/__results__.html\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/__notebook__.ipynb\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/__output__.json\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/custom.css\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/05/10.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/05/0.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/05/5.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/06/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/06/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/06/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/02/10.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/02/0.mov\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/02/5.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/04/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/04/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/04/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/03/10.mov\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/03/0.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/03/5.mov\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/01/10.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/01/0.mov\n",
      "/kaggle/input/drowsiness-dataset-fold1-1/Fold1_part1/01/5.mov\n",
      "/kaggle/input/facealignmentmodels/Fold_1_1.csv\n",
      "/kaggle/input/facealignmentmodels/shape_predictor_68_face_landmarks.dat\n",
      "/kaggle/input/facealignmentmodels/test_video2.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/__results__.html\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/__notebook__.ipynb\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/__output__.json\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/custom.css\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/17/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/17/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/17/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/18/10.mov\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/18/0.mov\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/18/5.mov\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/16/10.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/16/0.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/16/5.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/13/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/13/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/13/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/15/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/15/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/15/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/14/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/14/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold2-1/Fold2_part1/14/0.mp4\n",
      "/kaggle/input/drowsiness-batch-dataset-fold3-2/__results__.html\n",
      "/kaggle/input/drowsiness-batch-dataset-fold3-2/Fold_3_2.csv\n",
      "/kaggle/input/drowsiness-batch-dataset-fold3-2/__notebook__.ipynb\n",
      "/kaggle/input/drowsiness-batch-dataset-fold3-2/__output__.json\n",
      "/kaggle/input/drowsiness-batch-dataset-fold3-2/custom.css\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/__results__.html\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/__notebook__.ipynb\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/__output__.json\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/custom.css\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/27/10.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/27/0.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/27/5.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/25/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/25/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/25/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/28/10.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/28/0.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/28/5.MOV\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/26/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/26/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/26/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/30/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/30/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/30/0.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/29/5.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/29/10.mp4\n",
      "/kaggle/input/drowsiness-dataset-fold3-1/Fold3_part1/29/0.mp4\n"
     ]
    }
   ],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T15:49:18.106578Z",
     "iopub.status.busy": "2021-02-23T15:49:18.105730Z",
     "iopub.status.idle": "2021-02-23T15:49:18.324939Z",
     "shell.execute_reply": "2021-02-23T15:49:18.324333Z"
    },
    "papermill": {
     "duration": 0.284436,
     "end_time": "2021-02-23T15:49:18.325092",
     "exception": false,
     "start_time": "2021-02-23T15:49:18.040656",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T15:49:18.459545Z",
     "iopub.status.busy": "2021-02-23T15:49:18.458831Z",
     "iopub.status.idle": "2021-02-23T15:49:18.657547Z",
     "shell.execute_reply": "2021-02-23T15:49:18.655937Z"
    },
    "papermill": {
     "duration": 0.269225,
     "end_time": "2021-02-23T15:49:18.657704",
     "exception": false,
     "start_time": "2021-02-23T15:49:18.388479",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "def get_video_meta(video_path):\n",
    "    cap=cv2.VideoCapture(video_path)\n",
    "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    frame_count = cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "    duration = frame_count/fps\n",
    "    return {'fps':fps,'frame_count':frame_count, 'duration':duration }\n",
    "\n",
    "\n",
    "def get_path(x):\n",
    "    files = os.listdir(x)\n",
    "    return list(map(lambda file: os.path.join(x, file), files))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T15:49:18.791207Z",
     "iopub.status.busy": "2021-02-23T15:49:18.790515Z",
     "iopub.status.idle": "2021-02-23T15:49:26.482913Z",
     "shell.execute_reply": "2021-02-23T15:49:26.481965Z"
    },
    "papermill": {
     "duration": 7.765234,
     "end_time": "2021-02-23T15:49:26.483064",
     "exception": false,
     "start_time": "2021-02-23T15:49:18.717830",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_path = '../input/drowsiness-batch-dataset-fold1-1/Fold_1_1.csv'\n",
    "df = pd.read_csv(df_path, index_col = 0)\n",
    "\n",
    "df_path = '../input/drowsiness-batch-dataset-fold1-2/Fold_1_2.csv'\n",
    "df0 = pd.read_csv(df_path, index_col = 0)\n",
    "df = pd.concat([df,df0], ignore_index = True)\n",
    "\n",
    "df_path = '../input/drowsiness-batch-dataset-fold2-1/Fold_2_1.csv'\n",
    "df0 = pd.read_csv(df_path, index_col = 0)\n",
    "df = pd.concat([df,df0], ignore_index = True)\n",
    "\n",
    "df_path = '../input/fork-of-drowsiness-batch-dataset-fold2-2/Fold_2_2.csv'\n",
    "df0 = pd.read_csv(df_path, index_col = 0)\n",
    "df = pd.concat([df,df0], ignore_index = True)\n",
    "\n",
    "df_path = '../input/drowsiness-batch-dataset-fold3-1/Fold_3_1.csv'\n",
    "df0 = pd.read_csv(df_path, index_col = 0)\n",
    "df = pd.concat([df,df0], ignore_index = True)\n",
    "\n",
    "df_path = '../input/drowsiness-batch-dataset-fold3-2/Fold_3_2.csv'\n",
    "df0 = pd.read_csv(df_path, index_col = 0)\n",
    "df = pd.concat([df,df0], ignore_index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T15:49:26.608331Z",
     "iopub.status.busy": "2021-02-23T15:49:26.607552Z",
     "iopub.status.idle": "2021-02-23T15:49:26.612232Z",
     "shell.execute_reply": "2021-02-23T15:49:26.611651Z"
    },
    "papermill": {
     "duration": 0.068459,
     "end_time": "2021-02-23T15:49:26.612398",
     "exception": false,
     "start_time": "2021-02-23T15:49:26.543939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_files = [\n",
    "    '../input/drowsiness-dataset-fold1-1/Fold1_part1/06/0.mp4',\n",
    "    '../input/drowsiness-dataset-fold1-1/Fold1_part1/06/10.mp4',\n",
    "    '../input/drowsiness-dataset-fold1-1/Fold1_part1/06/5.mp4',\n",
    "    '../input/drowsiness-dataset-fold1-1/Fold1_part1/02/0.mov',\n",
    "    '../input/drowsiness-dataset-fold1-1/Fold1_part1/02/10.MOV',\n",
    "    '../input/drowsiness-dataset-fold1-1/Fold1_part1/02/5.MOV'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T15:49:26.756810Z",
     "iopub.status.busy": "2021-02-23T15:49:26.755832Z",
     "iopub.status.idle": "2021-02-23T15:49:26.770099Z",
     "shell.execute_reply": "2021-02-23T15:49:26.770645Z"
    },
    "papermill": {
     "duration": 0.094054,
     "end_time": "2021-02-23T15:49:26.770819",
     "exception": false,
     "start_time": "2021-02-23T15:49:26.676765",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>frame</th>\n",
       "      <th>file</th>\n",
       "      <th>label</th>\n",
       "      <th>x_min</th>\n",
       "      <th>y_min</th>\n",
       "      <th>x_max</th>\n",
       "      <th>y_max</th>\n",
       "      <th>l_18_x</th>\n",
       "      <th>l_18_y</th>\n",
       "      <th>...</th>\n",
       "      <th>l_63_x</th>\n",
       "      <th>l_63_y</th>\n",
       "      <th>l_64_x</th>\n",
       "      <th>l_64_y</th>\n",
       "      <th>l_65_x</th>\n",
       "      <th>l_65_y</th>\n",
       "      <th>l_66_x</th>\n",
       "      <th>l_66_y</th>\n",
       "      <th>l_67_x</th>\n",
       "      <th>l_67_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>../input/drowsiness-dataset-fold1-1/Fold1_part...</td>\n",
       "      <td>10</td>\n",
       "      <td>267</td>\n",
       "      <td>439</td>\n",
       "      <td>577</td>\n",
       "      <td>749</td>\n",
       "      <td>312</td>\n",
       "      <td>472</td>\n",
       "      <td>...</td>\n",
       "      <td>421</td>\n",
       "      <td>652</td>\n",
       "      <td>451</td>\n",
       "      <td>657</td>\n",
       "      <td>422</td>\n",
       "      <td>655</td>\n",
       "      <td>407</td>\n",
       "      <td>657</td>\n",
       "      <td>391</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>../input/drowsiness-dataset-fold1-1/Fold1_part...</td>\n",
       "      <td>10</td>\n",
       "      <td>267</td>\n",
       "      <td>439</td>\n",
       "      <td>577</td>\n",
       "      <td>749</td>\n",
       "      <td>312</td>\n",
       "      <td>471</td>\n",
       "      <td>...</td>\n",
       "      <td>421</td>\n",
       "      <td>651</td>\n",
       "      <td>452</td>\n",
       "      <td>657</td>\n",
       "      <td>421</td>\n",
       "      <td>655</td>\n",
       "      <td>406</td>\n",
       "      <td>657</td>\n",
       "      <td>391</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>../input/drowsiness-dataset-fold1-1/Fold1_part...</td>\n",
       "      <td>10</td>\n",
       "      <td>267</td>\n",
       "      <td>439</td>\n",
       "      <td>577</td>\n",
       "      <td>749</td>\n",
       "      <td>308</td>\n",
       "      <td>474</td>\n",
       "      <td>...</td>\n",
       "      <td>418</td>\n",
       "      <td>653</td>\n",
       "      <td>450</td>\n",
       "      <td>658</td>\n",
       "      <td>418</td>\n",
       "      <td>657</td>\n",
       "      <td>403</td>\n",
       "      <td>658</td>\n",
       "      <td>388</td>\n",
       "      <td>657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>../input/drowsiness-dataset-fold1-1/Fold1_part...</td>\n",
       "      <td>10</td>\n",
       "      <td>267</td>\n",
       "      <td>439</td>\n",
       "      <td>577</td>\n",
       "      <td>749</td>\n",
       "      <td>306</td>\n",
       "      <td>475</td>\n",
       "      <td>...</td>\n",
       "      <td>417</td>\n",
       "      <td>654</td>\n",
       "      <td>448</td>\n",
       "      <td>658</td>\n",
       "      <td>418</td>\n",
       "      <td>656</td>\n",
       "      <td>403</td>\n",
       "      <td>658</td>\n",
       "      <td>388</td>\n",
       "      <td>656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>../input/drowsiness-dataset-fold1-1/Fold1_part...</td>\n",
       "      <td>10</td>\n",
       "      <td>267</td>\n",
       "      <td>439</td>\n",
       "      <td>577</td>\n",
       "      <td>749</td>\n",
       "      <td>305</td>\n",
       "      <td>474</td>\n",
       "      <td>...</td>\n",
       "      <td>417</td>\n",
       "      <td>651</td>\n",
       "      <td>448</td>\n",
       "      <td>655</td>\n",
       "      <td>418</td>\n",
       "      <td>654</td>\n",
       "      <td>404</td>\n",
       "      <td>656</td>\n",
       "      <td>389</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 108 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   id  frame                                               file  label  x_min  \\\n",
       "0   0      0  ../input/drowsiness-dataset-fold1-1/Fold1_part...     10    267   \n",
       "1   0      2  ../input/drowsiness-dataset-fold1-1/Fold1_part...     10    267   \n",
       "2   0      4  ../input/drowsiness-dataset-fold1-1/Fold1_part...     10    267   \n",
       "3   0      6  ../input/drowsiness-dataset-fold1-1/Fold1_part...     10    267   \n",
       "4   0      8  ../input/drowsiness-dataset-fold1-1/Fold1_part...     10    267   \n",
       "\n",
       "   y_min  x_max  y_max  l_18_x  l_18_y  ...  l_63_x  l_63_y  l_64_x  l_64_y  \\\n",
       "0    439    577    749     312     472  ...     421     652     451     657   \n",
       "1    439    577    749     312     471  ...     421     651     452     657   \n",
       "2    439    577    749     308     474  ...     418     653     450     658   \n",
       "3    439    577    749     306     475  ...     417     654     448     658   \n",
       "4    439    577    749     305     474  ...     417     651     448     655   \n",
       "\n",
       "   l_65_x  l_65_y  l_66_x  l_66_y  l_67_x  l_67_y  \n",
       "0     422     655     407     657     391     655  \n",
       "1     421     655     406     657     391     655  \n",
       "2     418     657     403     658     388     657  \n",
       "3     418     656     403     658     388     656  \n",
       "4     418     654     404     656     389     655  \n",
       "\n",
       "[5 rows x 108 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T15:49:26.921732Z",
     "iopub.status.busy": "2021-02-23T15:49:26.920885Z",
     "iopub.status.idle": "2021-02-23T15:49:33.482828Z",
     "shell.execute_reply": "2021-02-23T15:49:33.482228Z"
    },
    "papermill": {
     "duration": 6.650705,
     "end_time": "2021-02-23T15:49:33.482973",
     "exception": false,
     "start_time": "2021-02-23T15:49:26.832268",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/05/10.MOV\n",
      "56\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/05/0.MOV\n",
      "57\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/05/5.MOV\n",
      "57\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/06/5.mp4\n",
      "38\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/06/10.mp4\n",
      "32\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/06/0.mp4\n",
      "37\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/02/10.MOV\n",
      "60\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/02/0.mov\n",
      "60\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/02/5.MOV\n",
      "60\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/04/5.mp4\n",
      "55\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/04/10.mp4\n",
      "51\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/04/0.mp4\n",
      "48\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/03/10.mov\n",
      "61\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/03/0.MOV\n",
      "47\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/03/5.mov\n",
      "60\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/01/10.MOV\n",
      "59\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/01/0.mov\n",
      "60\n",
      "../input/drowsiness-dataset-fold1-1/Fold1_part1/01/5.mov\n",
      "59\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/07/5.mp4\n",
      "59\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/07/10.mp4\n",
      "59\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/07/0.mp4\n",
      "59\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/10/10.MOV\n",
      "62\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/10/0.MOV\n",
      "54\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/10/5.MOV\n",
      "62\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/12/5.mp4\n",
      "60\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/12/10.mp4\n",
      "49\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/12/0.mp4\n",
      "56\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/08/5.mp4\n",
      "59\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/08/10.mp4\n",
      "58\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/08/0.mp4\n",
      "59\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/09/5.mp4\n",
      "58\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/09/10.mp4\n",
      "66\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/09/0.mp4\n",
      "60\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/11/5.mp4\n",
      "32\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/11/10.mp4\n",
      "34\n",
      "../input/drowsiness-dataset-fold1-2/Fold1_part2/11/0.mp4\n",
      "62\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/17/5.mp4\n",
      "60\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/17/10.mp4\n",
      "59\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/17/0.mp4\n",
      "60\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/18/10.mov\n",
      "25\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/18/0.mov\n",
      "38\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/18/5.mov\n",
      "29\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/16/10.MOV\n",
      "47\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/16/0.MOV\n",
      "37\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/16/5.MOV\n",
      "32\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/13/5.mp4\n",
      "68\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/13/10.mp4\n",
      "61\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/13/0.mp4\n",
      "60\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/15/5.mp4\n",
      "59\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/15/10.mp4\n",
      "61\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/15/0.mp4\n",
      "58\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/14/5.mp4\n",
      "65\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/14/10.mp4\n",
      "62\n",
      "../input/drowsiness-dataset-fold2-1/Fold2_part1/14/0.mp4\n",
      "61\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/19/10.MOV\n",
      "60\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/19/0.MOV\n",
      "57\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/19/5.MOV\n",
      "60\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/22/10.MOV\n",
      "61\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/22/0.MOV\n",
      "60\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/22/5.MOV\n",
      "60\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/23/5.mp4\n",
      "55\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/23/10.mp4\n",
      "57\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/23/0.mp4\n",
      "57\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/20/10.mp4\n",
      "71\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/20/0.mp4\n",
      "62\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/20/5.MOV\n",
      "60\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/21/10.MOV\n",
      "60\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/21/0.MOV\n",
      "60\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/21/5.MOV\n",
      "60\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/24/5.mp4\n",
      "36\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/24/10.mp4\n",
      "38\n",
      "../input/drowsiness-dataset-fold2-2/Fold2_part2/24/0.mp4\n",
      "36\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/27/10.MOV\n",
      "61\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/27/0.MOV\n",
      "63\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/27/5.MOV\n",
      "62\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/25/5.mp4\n",
      "56\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/25/10.mp4\n",
      "59\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/25/0.mp4\n",
      "59\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/28/10.MOV\n",
      "49\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/28/0.MOV\n",
      "55\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/28/5.MOV\n",
      "47\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/26/5.mp4\n",
      "82\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/26/10.mp4\n",
      "60\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/26/0.mp4\n",
      "61\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/30/5.mp4\n",
      "69\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/30/10.mp4\n",
      "60\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/30/0.mp4\n",
      "68\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/29/5.mp4\n",
      "27\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/29/10.mp4\n",
      "35\n",
      "../input/drowsiness-dataset-fold3-1/Fold3_part1/29/0.mp4\n",
      "63\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/35/5.mp4\n",
      "56\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/35/10.mp4\n",
      "66\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/35/0.mp4\n",
      "58\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/36/5.mp4\n",
      "62\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/36/10.mp4\n",
      "62\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/36/0.mp4\n",
      "62\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/32/5.mp4\n",
      "45\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/32/10_1.mp4\n",
      "28\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/32/0.mp4\n",
      "35\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/32/10_2.mp4\n",
      "12\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/31/5.mp4\n",
      "20\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/31/10.mp4\n",
      "53\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/31/0.mp4\n",
      "54\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/34/10.mp4\n",
      "61\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/34/0.mov\n",
      "38\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/34/5.mov\n",
      "68\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/33/5.mp4\n",
      "28\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/33/10.mp4\n",
      "55\n",
      "../input/drowsiness-dataset-fold3-2/Fold3_part2/33/0.mp4\n",
      "58\n"
     ]
    }
   ],
   "source": [
    "files = df.file.unique()\n",
    "for file in files :\n",
    "    print(file)\n",
    "    df_f = df[df.file == file]\n",
    "    print(df_f.id.values.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T15:49:33.662015Z",
     "iopub.status.busy": "2021-02-23T15:49:33.661283Z",
     "iopub.status.idle": "2021-02-23T15:49:33.881988Z",
     "shell.execute_reply": "2021-02-23T15:49:33.881403Z"
    },
    "papermill": {
     "duration": 0.329507,
     "end_time": "2021-02-23T15:49:33.882139",
     "exception": false,
     "start_time": "2021-02-23T15:49:33.552632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_df = df[~df.file.isin(test_files)]\n",
    "test_df = df[df.file.isin(test_files)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T15:49:34.073613Z",
     "iopub.status.busy": "2021-02-23T15:49:34.057852Z",
     "iopub.status.idle": "2021-02-23T15:49:34.084033Z",
     "shell.execute_reply": "2021-02-23T15:49:34.084520Z"
    },
    "papermill": {
     "duration": 0.131375,
     "end_time": "2021-02-23T15:49:34.084686",
     "exception": false,
     "start_time": "2021-02-23T15:49:33.953311",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class VideoFrameDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 annotation_df: pd.DataFrame,\n",
    "                 num_segments: int = 3,\n",
    "                 frames_per_segment: int = 1,\n",
    "                 transform = None,\n",
    "                 e2e: bool = False, #if not e2e then crop face\n",
    "                 jump_frame: int = 1,\n",
    "                 meta_df = None,\n",
    "                 file_name = None\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Paramters:\n",
    "            annotation_df: DataFrame prepare with the format similar to the dataframe above\n",
    "            num_segments: number of datapoint per clip\n",
    "            frames_per_segment: number of frame use in a datapoint\n",
    "            e2e: \n",
    "                if True data used for end to end model / image is not cropped\n",
    "                if False each frame is cropped to the bounding box of users face\n",
    "            jump_frame: number of index jump in for frames in the index \n",
    "                (e.g: jump_frame=2, dataset[0] will be using clip1 at row with index 0,2,4,6,8 - (in this case frames_per_segment=5)) \n",
    "                (e.g: jump_frame=0, dataset[0] will be using clip1 at row with index 0,1,2,3 - (in this case frames_per_segment=4)) \n",
    "        \n",
    "        \"\"\"\n",
    "        super(VideoFrameDataset, self).__init__()\n",
    "\n",
    "        \n",
    "        \n",
    "        \"\"\"\n",
    "        self.annotation_df_list is contains multiple df\n",
    "            Each dataframe store annotation detail for 1 clip\n",
    "        \"\"\"\n",
    "        annotation_df_list = []\n",
    "        meta_dict_list = []\n",
    "        \n",
    "        self.e2e = e2e\n",
    "#         if not self.e2e:\n",
    "#             annotation_df = resize_keypoints(annotation_df, new_shape = (300,300))\n",
    "      \n",
    "        \n",
    "        for video_path, df in tqdm(annotation_df.groupby('file')):\n",
    "                annotation_df_list.append(df.sort_values(by=['frame']).reset_index(drop=True))\n",
    "        \n",
    "        \n",
    "        if (not meta_df is None):\n",
    "            self.meta_df = meta_df\n",
    "        else:\n",
    "            for video_path, df in tqdm(annotation_df.groupby('file')):\n",
    "                dic = {}\n",
    "                dic['video_path'] = video_path\n",
    "\n",
    "                #TODO: move this to preprocessing step in which time stamp is calculated during df preparation step\n",
    "                time_stamps, fps = torchvision.io.read_video_timestamps(video_path, pts_unit='sec')\n",
    "                temp_time_stamps = time_stamps\n",
    "                dic['time_stamps'] = time_stamps\n",
    "                dic['fps'] = fps\n",
    "                # add dataframe into list variable - reset index of every individual \n",
    "                meta_dict_list.append(dic)\n",
    "                self.meta_df = pd.DataFrame(meta_dict_list)\n",
    "                self.meta_df.to_pickle(file_name)\n",
    "\n",
    "\n",
    "        self.annotation_df_list = annotation_df_list\n",
    "        self.video_num = len(self.annotation_df_list)\n",
    "        self.num_segments = num_segments\n",
    "\n",
    "        \n",
    "        assert frames_per_segment >=1, 'frames_per_segment less then one'\n",
    "        self.frames_per_segment = frames_per_segment            \n",
    "        self.jump_frame = jump_frame\n",
    "        self.landmark_cols = self.get_facial_landmarks(annotation_df) \n",
    "        self.transform = transform\n",
    "        \n",
    "        \n",
    "            \n",
    "\n",
    "        \n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.video_num*self.frames_per_segment\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        #check index is not larger than lenght of data\n",
    "#         assert index < self.__len__()\n",
    "        row = self.index2row(index)\n",
    "        \n",
    "        # declare variable to use\n",
    "        video_path = row['file'][0]\n",
    "        dic = self.meta_df[self.meta_df['video_path'] == video_path].iloc[0]\n",
    "        \n",
    "        frames = row['frame'].values\n",
    "        fps = dic['fps']\n",
    "        \n",
    "        label = row['label'][0]\n",
    "        label = self.convert_label(label)\n",
    "        landmark_columns = row[self.landmark_cols]\n",
    "        if self.e2e:\n",
    "            frame = elf.read_specific_frame(frames[0], video_path, dic['time_stamps'])\n",
    "        else:\n",
    "            bbox = row[['y_min', 'y_max', 'x_min', 'x_max']].values[0]\n",
    "            frame = self.read_specific_frame(\n",
    "                frames[0], \n",
    "                video_path, \n",
    "                dic['time_stamps'], \n",
    "                face_bbox=bbox\n",
    "            )\n",
    "            landmark_columns = self.convert_facial_landmark_coordinate(row)\n",
    "        ################################\n",
    "        \n",
    "        # Read frame from video and concat them into 1 tensor\n",
    "#         video_tensor = torch.cat(video_tensor)\n",
    "        \n",
    "        return frame[0], label, landmark_columns.values\n",
    "\n",
    "    \n",
    "    \n",
    "    def read_specific_frame(self, frame, video_path, time_stamps, face_bbox=None, transforms=None):\n",
    "        \"\"\"\n",
    "        Return a specific frame in the video clip\n",
    "        \"\"\"\n",
    "        index = time_stamps[frame]\n",
    "        start_pts = end_pts = time_stamps[frame]\n",
    "        vframe, aframe, info = torchvision.io.read_video(\n",
    "            video_path, \n",
    "            start_pts=start_pts, \n",
    "            end_pts=end_pts, \n",
    "            pts_unit='sec'\n",
    "        )\n",
    "        file_type = video_path.split('.')[-1]\n",
    "        if file_type != 'mp4' :\n",
    "            vframe = vframe.permute(0,2,1,3)\n",
    "            vframe = torch.flip(vframe, [2])\n",
    "\n",
    "        if (not face_bbox is None):\n",
    "            y_min, y_max, x_min, x_max = face_bbox\n",
    "            x_min = 0 if x_min < 0 else x_min\n",
    "            y_min = 0 if y_min < 0 else y_min\n",
    "            # video is on the in the correct orientation (inverse orientation)\n",
    "            vframe = vframe[:,y_min:y_max, x_min:x_max, :]\n",
    "            \n",
    "            # resize vframe so that all face have the same size\n",
    "            vframe =  vframe.permute(0,3,1,2)\n",
    "            vframe = F.interpolate(vframe, (300, 300))\n",
    "            vframe = vframe.permute(0,2,3,1)        \n",
    "        return vframe\n",
    "    \n",
    "    \n",
    "    def convert_label(self, input_label):\n",
    "        label_mapping = {\n",
    "            0:0,\n",
    "            5:1,\n",
    "            10:2\n",
    "        }\n",
    "        return label_mapping[input_label]\n",
    "        \n",
    "    \n",
    "    \n",
    "    def get_facial_landmarks(self, df, combined=True):\n",
    "        facial_landmarks_x, facial_landmarks_y = [], []\n",
    "        for i in df.keys():\n",
    "            if(i.split('_')[0]=='l') and i.split('_')[-1]=='x':\n",
    "                facial_landmarks_x.append(i)\n",
    "            elif (i.split('_')[0]=='l') and i.split('_')[-1]=='y':\n",
    "                facial_landmarks_y.append(i)\n",
    "        if combined:\n",
    "            return facial_landmarks_x + facial_landmarks_y\n",
    "        else:\n",
    "            return facial_landmarks_x, facial_landmarks_y\n",
    "\n",
    "\n",
    "    def get_landmark(self, row, landmark_num):\n",
    "        x,y = row[f\"l_{landmark_num}_x\", f\"l_{landmark_num}_y\"].values\n",
    "        return x,y\n",
    "    \n",
    "    def convert_facial_landmark_coordinate(self, row, new_shape=(300,300)):\n",
    "        df = deepcopy(row)\n",
    "        x_col, y_col = self.get_facial_landmarks(df, combined=False)\n",
    "        x_df = df[x_col].sub(df['x_min'], axis=0)\n",
    "        y_df = df[y_col].sub(df['y_min'], axis=0)\n",
    "        \n",
    "        \n",
    "        face_bbox = df[['x_min', 'y_min', 'x_max', 'y_max']]\n",
    "\n",
    "        y_scale = (face_bbox['y_max'] - face_bbox['y_min']) / new_shape[0]\n",
    "        x_scale = (face_bbox['x_max'] - face_bbox['x_min']) / new_shape[1] \n",
    "        \n",
    "        x_df = x_df.divide(x_scale, axis=0)\n",
    "        y_df = y_df.divide(y_scale, axis=0)\n",
    "        return pd.DataFrame.join(x_df, y_df)\n",
    "\n",
    "        \n",
    "    \n",
    "    def index2row(self, index):\n",
    "        \"\"\"\n",
    "        self.annotation_df_list is contains multiple df\n",
    "            Each dataframe store annotation detail for 1 clip\n",
    "            This function convert index used by pytorch dataset into the rows annotation dataframe\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        video_index = index % self.video_num\n",
    "        df = self.annotation_df_list[video_index]\n",
    "        row_index = index//self.video_num * (len(df) // self.num_segments)\n",
    "        \n",
    "        #careful with case of data point at the end of the video clip        \n",
    "        rows_index = []\n",
    "        for i in range(self.frames_per_segment):\n",
    "            rows_index.append(row_index+(i*self.jump_frame))\n",
    "            # frame jump to too far ahead in video, simply get datapoint as a list of index [-self.frames_per_segment:]\n",
    "            if (df.index.max() < max(rows_index)):\n",
    "                return df.iloc[-self.frames_per_segment:].reset_index(drop=True)\n",
    "        return df.iloc[rows_index].reset_index(drop=True)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T15:49:34.243391Z",
     "iopub.status.busy": "2021-02-23T15:49:34.241296Z",
     "iopub.status.idle": "2021-02-23T15:49:34.244184Z",
     "shell.execute_reply": "2021-02-23T15:49:34.244777Z"
    },
    "papermill": {
     "duration": 0.087301,
     "end_time": "2021-02-23T15:49:34.244956",
     "exception": false,
     "start_time": "2021-02-23T15:49:34.157655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_facial_landmarks(df, combined=True):\n",
    "        facial_landmarks_x, facial_landmarks_y = [], []\n",
    "        for i in df.keys():\n",
    "            if(i.split('_')[0]=='l') and i.split('_')[-1]=='x':\n",
    "                facial_landmarks_x.append(i)\n",
    "            elif (i.split('_')[0]=='l') and i.split('_')[-1]=='y':\n",
    "                facial_landmarks_y.append(i)\n",
    "        if combined:\n",
    "            return facial_landmarks_x + facial_landmarks_y\n",
    "        else:\n",
    "            return facial_landmarks_x, facial_landmarks_y\n",
    "\n",
    "def resize_keypoints(df, new_shape = (300,300)):\n",
    "    \"\"\"\n",
    "    - Input:\n",
    "        1. Tuple of original data shape\n",
    "        2. Tuple of key_points data\n",
    "        3. Tuple of desired shape.\n",
    "    - Output:\n",
    "        1. A tuple of resized key_points\n",
    "    \"\"\"\n",
    "    facial_landmarks_x, facial_landmarks_y = get_facial_landmarks(df, combined=False)\n",
    "    face_bbox = df[['x_min', 'y_min', 'x_max', 'y_max']]\n",
    "#     print(  x_min, y_min, x_max, y_max )\n",
    "#     print(df)\n",
    "    \n",
    "    \n",
    "    # Scalling factor\n",
    "#     print((face_bbox['y_max'] - face_bbox['y_min']).values)\n",
    "#     print(face_bbox['x_max'] - face_bbox['x_min'].values)\n",
    "        \n",
    "    y_scale = new_shape[0] / (face_bbox['y_max'] - face_bbox['y_min'])\n",
    "    x_scale = new_shape[1] / (face_bbox['x_max'] - face_bbox['x_min']) \n",
    "#     df[facial_landmarks_x] = df[facial_landmarks_x] / x_scale\n",
    "#     df[facial_landmarks_y] = df[facial_landmarks_y] / y_scale\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T15:49:34.403420Z",
     "iopub.status.busy": "2021-02-23T15:49:34.402390Z",
     "iopub.status.idle": "2021-02-23T20:06:41.543383Z",
     "shell.execute_reply": "2021-02-23T20:06:41.541767Z"
    },
    "papermill": {
     "duration": 15427.223347,
     "end_time": "2021-02-23T20:06:41.543521",
     "exception": false,
     "start_time": "2021-02-23T15:49:34.320174",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 103/103 [00:00<00:00, 173.64it/s]\n",
      "100%|██████████| 103/103 [3:56:26<00:00, 137.73s/it]\n",
      "100%|██████████| 6/6 [00:00<00:00, 159.38it/s]\n",
      "100%|██████████| 6/6 [20:40<00:00, 206.67s/it]\n"
     ]
    }
   ],
   "source": [
    "from copy import deepcopy \n",
    "\n",
    "train_dataset = VideoFrameDataset(\n",
    "    annotation_df = train_df,\n",
    "    num_segments = 50,\n",
    "    frames_per_segment = 10,\n",
    "    transform = None,\n",
    "    jump_frame = 1,\n",
    "    e2e = False,\n",
    "    meta_df = None,\n",
    "    file_name = 'meta_train.pkl'\n",
    ")\n",
    "test_dataset = VideoFrameDataset(\n",
    "    annotation_df = test_df,\n",
    "    num_segments = 50,\n",
    "    frames_per_segment = 10,\n",
    "    transform = None,\n",
    "    jump_frame = 1,\n",
    "    e2e = False,\n",
    "    meta_df = None,\n",
    "    file_name = 'meta_test.pkl'\n",
    ")\n",
    "\n",
    "trainloader = DataLoader(train_dataset, batch_size=50, shuffle=True)\n",
    "testloader = DataLoader(test_dataset, batch_size=30, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:41.820506Z",
     "iopub.status.busy": "2021-02-23T20:06:41.818693Z",
     "iopub.status.idle": "2021-02-23T20:06:41.821143Z",
     "shell.execute_reply": "2021-02-23T20:06:41.821625Z"
    },
    "papermill": {
     "duration": 0.120215,
     "end_time": "2021-02-23T20:06:41.821775",
     "exception": false,
     "start_time": "2021-02-23T20:06:41.701560",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def generate_optical_flow(batch_landmarks) :\n",
    "    b, l, s = batch_landmarks.shape\n",
    "    optical_flow = np.zeros((b,2*l-2,300,300))\n",
    "    for i_b in range(b) :\n",
    "        landmarks = batch_landmarks[i_b]\n",
    "        dx = np.zeros((l-1,300,300), dtype = np.int8)\n",
    "        dy = np.zeros((l-1,300,300), dtype = np.int8)\n",
    "        diff = (landmarks[1:] - landmarks[:-1]) * 3\n",
    "        for i in range(0, l-1) :\n",
    "            coor = landmarks[i].reshape(2,-1).T\n",
    "            d = diff[i].reshape(2,-1).T\n",
    "            for j in range(0, len(coor)) :\n",
    "                x = int(coor[j][0])\n",
    "                y = int(coor[j][1])\n",
    "                x = 0 if x < 0 else x\n",
    "                y = 0 if y < 0 else y\n",
    "                y = 299 if y > 299 else y\n",
    "                x = 299 if x > 299 else x\n",
    "                dx[i][x][y] = int(d[j][0])\n",
    "                dy[i][x][y] = int(d[j][1])\n",
    "            optical_flow[i_b,:l-1,:,:] = dx\n",
    "            optical_flow[i_b,l-1:,:,:] = dx\n",
    "    return optical_flow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:42.033876Z",
     "iopub.status.busy": "2021-02-23T20:06:42.033101Z",
     "iopub.status.idle": "2021-02-23T20:06:42.036974Z",
     "shell.execute_reply": "2021-02-23T20:06:42.036478Z"
    },
    "papermill": {
     "duration": 0.11198,
     "end_time": "2021-02-23T20:06:42.037099",
     "exception": false,
     "start_time": "2021-02-23T20:06:41.925119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import models\n",
    "from torch import nn, optim\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:42.677161Z",
     "iopub.status.busy": "2021-02-23T20:06:42.676168Z",
     "iopub.status.idle": "2021-02-23T20:06:42.679767Z",
     "shell.execute_reply": "2021-02-23T20:06:42.678823Z"
    },
    "papermill": {
     "duration": 0.537206,
     "end_time": "2021-02-23T20:06:42.679912",
     "exception": false,
     "start_time": "2021-02-23T20:06:42.142706",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = 'cuda:0' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:42.898184Z",
     "iopub.status.busy": "2021-02-23T20:06:42.897413Z",
     "iopub.status.idle": "2021-02-23T20:06:48.451517Z",
     "shell.execute_reply": "2021-02-23T20:06:48.450963Z"
    },
    "papermill": {
     "duration": 5.665482,
     "end_time": "2021-02-23T20:06:48.451671",
     "exception": false,
     "start_time": "2021-02-23T20:06:42.786189",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/resnet101-5d3b4d8f.pth\" to /root/.cache/torch/hub/checkpoints/resnet101-5d3b4d8f.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f3e6d3fbfa44c9b7bcb1018f67eef3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/170M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spatial_model = models.resnet101(pretrained = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:48.670359Z",
     "iopub.status.busy": "2021-02-23T20:06:48.669521Z",
     "iopub.status.idle": "2021-02-23T20:06:48.675647Z",
     "shell.execute_reply": "2021-02-23T20:06:48.676109Z"
    },
    "papermill": {
     "duration": 0.118506,
     "end_time": "2021-02-23T20:06:48.676272",
     "exception": false,
     "start_time": "2021-02-23T20:06:48.557766",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (6): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (7): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (8): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (9): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (10): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (11): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (12): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (13): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (14): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (15): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (16): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (17): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (18): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (19): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (20): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (21): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (22): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spatial_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:48.893773Z",
     "iopub.status.busy": "2021-02-23T20:06:48.892995Z",
     "iopub.status.idle": "2021-02-23T20:06:53.447810Z",
     "shell.execute_reply": "2021-02-23T20:06:53.447167Z"
    },
    "papermill": {
     "duration": 4.665132,
     "end_time": "2021-02-23T20:06:53.447986",
     "exception": false,
     "start_time": "2021-02-23T20:06:48.782854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "spatial_model.fc = nn.Linear(2048, 3, bias = True)\n",
    "for params in spatial_model.parameters() :\n",
    "    params.requires_grad = False\n",
    "    \n",
    "spatial_model.fc.weight.requires_grad = True\n",
    "spatial_model.fc.bias.requires_grad = True\n",
    "\n",
    "adam_spatial = optim.Adam(\n",
    "    filter(lambda p : p.requires_grad, spatial_model.parameters()), \n",
    "    lr=1e-4\n",
    ")\n",
    "spatial_model = spatial_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:53.668130Z",
     "iopub.status.busy": "2021-02-23T20:06:53.666853Z",
     "iopub.status.idle": "2021-02-23T20:06:53.669334Z",
     "shell.execute_reply": "2021-02-23T20:06:53.669866Z"
    },
    "papermill": {
     "duration": 0.115126,
     "end_time": "2021-02-23T20:06:53.670047",
     "exception": false,
     "start_time": "2021-02-23T20:06:53.554921",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision import transforms\n",
    "\n",
    "transformation = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(\n",
    "        mean = [0.485, 0.456, 0.406],\n",
    "        std = [0.229, 0.224, 0.225]\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:53.898852Z",
     "iopub.status.busy": "2021-02-23T20:06:53.898181Z",
     "iopub.status.idle": "2021-02-23T20:06:55.674516Z",
     "shell.execute_reply": "2021-02-23T20:06:55.675994Z"
    },
    "papermill": {
     "duration": 1.897581,
     "end_time": "2021-02-23T20:06:55.676222",
     "exception": false,
     "start_time": "2021-02-23T20:06:53.778641",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/21 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "101",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-b49202bf1ddd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mloss_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0me\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtqdm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m         \u001b[0mframes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlandmarks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mframes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mframes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/tqdm/std.py\u001b[0m in \u001b[0;36m__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1165\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1166\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1167\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0mobj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1168\u001b[0m                 \u001b[0;32myield\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1169\u001b[0m                 \u001b[0;31m# Update and possibly print the progressbar.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 435\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    473\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    474\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 475\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    476\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    477\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-99abc66e7fb3>\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     94\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'label'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 95\u001b[0;31m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_label\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     96\u001b[0m         \u001b[0mlandmark_columns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlandmark_cols\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     97\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0me2e\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-99abc66e7fb3>\u001b[0m in \u001b[0;36mconvert_label\u001b[0;34m(self, input_label)\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         }\n\u001b[0;32m--> 154\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mlabel_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minput_label\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 101"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "train_losses = []\n",
    "train_acc = []\n",
    "test_losses = []\n",
    "test_acc = []\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "for e in range(epochs) :\n",
    "    for data in tqdm(trainloader) :\n",
    "        frames, labels, landmarks = data\n",
    "        frames = frames.float()\n",
    "        frame = frame.permute(0,3,1,2).to(device)\n",
    "        frame = transformation(frame)\n",
    "        labels = labels.long().to(device)\n",
    "        adam_spatial.zero_grad()\n",
    "        out = spatial_model(frames)\n",
    "        out = F.softmax(out, dim=1)\n",
    "        loss = loss_func(out, label)\n",
    "        loss.backward()\n",
    "        adam_spatial.step()\n",
    "        train_losses.append(loss.item())\n",
    "        with torch.no_grad() :\n",
    "            spatial_pred = out.argmax(axis=1)\n",
    "            train_acc.append(torch.sum(spatial_pred == label)/len(label))\n",
    "            test_loss = 0.0\n",
    "            test_accuracy = 0.0\n",
    "            for data in testloader :\n",
    "                frames, labels, landmarks = data\n",
    "                frames = frames.float()\n",
    "                frame = frame.permute(0,3,1,2).to(device)\n",
    "                frame = transformation(frame)\n",
    "                labels = labels.long().to(device)\n",
    "                adam_spatial.zero_grad()\n",
    "                out = spatial_model(frames)\n",
    "                out = F.softmax(out, dim=1)\n",
    "                loss = loss_func(out, label)\n",
    "                test_loss += loss.item()\n",
    "                spatial_pred = out.argmax(axis=1) \n",
    "                test_accuracy += torch.sum(spatial_pred == label)/len(label)\n",
    "            test_losses.append(test_loss/len(testloader))\n",
    "            test_acc.append(test_accuracy/len(testloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:55.949446Z",
     "iopub.status.busy": "2021-02-23T20:06:55.948808Z",
     "iopub.status.idle": "2021-02-23T20:06:56.086202Z",
     "shell.execute_reply": "2021-02-23T20:06:56.086724Z"
    },
    "papermill": {
     "duration": 0.264926,
     "end_time": "2021-02-23T20:06:56.086899",
     "exception": false,
     "start_time": "2021-02-23T20:06:55.821973",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAD4CAYAAADhNOGaAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/Il7ecAAAACXBIWXMAAAsTAAALEwEAmpwYAAAOHUlEQVR4nO3c34tc533H8fenUkQJSbFdybYsyV011UXVUogYhCG9CPUPJMVYvuiFDYmFcyEMNTi0wVXqf8CJoTGmxkakBpm4mEASIoyCYru5VeqVY8uoiuONSKqNFHuTCyfgCyHy7cUetevNSDu7Z1a76+f9gmHmnPOcmedhwG/NmVmnqpAkteuPVnoCkqSVZQgkqXGGQJIaZwgkqXGGQJIat36lJ7AUGzdurImJiZWehiStKSdPnvx1VW2av39NhmBiYoLJycmVnoYkrSlJfjFsv5eGJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxYwlBkj1J3k4yleTQkONJ8lR3/FSSXfOOr0vy4yQvjWM+kqTR9Q5BknXA08BeYCdwf5Kd84btBXZ0t4PAM/OOPwKc6TsXSdLijeMTwW5gqqrOVtVF4EVg/7wx+4Hna9YJ4LokmwGSbAU+B3xjDHORJC3SOEKwBTg3Z3u62zfqmCeBR4HfX+1FkhxMMplkcmZmpteEJUn/bxwhyJB9NcqYJHcD71XVyYVepKoOV9WgqgabNm1ayjwlSUOMIwTTwLY521uB8yOO+QxwT5KfM3tJ6e+SfHMMc5IkjWgcIXgN2JFke5INwH3A0XljjgIPdL8eug14v6ouVNVXqmprVU105/1nVX1+DHOSJI1ofd8nqKpLSR4GjgPrgOeq6nSSh7rjzwLHgH3AFPAB8GDf15UkjUeq5l/OX/0Gg0FNTk6u9DQkaU1JcrKqBvP3+5fFktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjTMEktQ4QyBJjRtLCJLsSfJ2kqkkh4YcT5KnuuOnkuzq9m9L8sMkZ5KcTvLIOOYjSRpd7xAkWQc8DewFdgL3J9k5b9heYEd3Owg80+2/BPxTVf0lcBvwD0POlSQto3F8ItgNTFXV2aq6CLwI7J83Zj/wfM06AVyXZHNVXaiq1wGq6nfAGWDLGOYkSRrROEKwBTg3Z3uaP/yP+YJjkkwAnwZ+NIY5SZJGNI4QZMi+WsyYJJ8Avg18qap+O/RFkoNJJpNMzszMLHmykqQPG0cIpoFtc7a3AudHHZPkY8xG4IWq+s6VXqSqDlfVoKoGmzZtGsO0JUkwnhC8BuxIsj3JBuA+4Oi8MUeBB7pfD90GvF9VF5IE+HfgTFX96xjmIklapPV9n6CqLiV5GDgOrAOeq6rTSR7qjj8LHAP2AVPAB8CD3emfAb4AvJXkjW7fv1TVsb7zkiSNJlXzL+evfoPBoCYnJ1d6GpK0piQ5WVWD+fv9y2JJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJapwhkKTGGQJJatxYQpBkT5K3k0wlOTTkeJI81R0/lWTXqOdKkpZX7xAkWQc8DewFdgL3J9k5b9heYEd3Owg8s4hzJUnLaByfCHYDU1V1tqouAi8C++eN2Q88X7NOANcl2TziuZKkZTSOEGwBzs3Znu72jTJmlHMBSHIwyWSSyZmZmd6TliTNGkcIMmRfjThmlHNnd1YdrqpBVQ02bdq0yClKkq5k/RieYxrYNmd7K3B+xDEbRjhXkrSMxvGJ4DVgR5LtSTYA9wFH5405CjzQ/XroNuD9qrow4rmSpGXU+xNBVV1K8jBwHFgHPFdVp5M81B1/FjgG7AOmgA+AB692bt85SZJGl6qhl+RXtcFgUJOTkys9DUlaU5KcrKrB/P3+ZbEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjDIEkNc4QSFLjeoUgyQ1JXk7yTnd//RXG7UnydpKpJIfm7H8iyU+SnEry3STX9ZmPJGnx+n4iOAS8WlU7gFe77Q9Jsg54GtgL7ATuT7KzO/wy8NdV9TfAT4Gv9JyPJGmR+oZgP3Cke3wEuHfImN3AVFWdraqLwIvdeVTVD6rqUjfuBLC153wkSYvUNwQ3VdUFgO7+xiFjtgDn5mxPd/vm+yLw/Z7zkSQt0vqFBiR5Bbh5yKHHRnyNDNlX817jMeAS8MJV5nEQOAhw6623jvjSkqSFLBiCqrrjSseSvJtkc1VdSLIZeG/IsGlg25ztrcD5Oc9xALgbuL2qiiuoqsPAYYDBYHDFcZKkxel7aegocKB7fAD43pAxrwE7kmxPsgG4rzuPJHuAfwbuqaoPes5FkrQEfUPwOHBnkneAO7ttktyS5BhA92Xww8Bx4Azwrao63Z3/b8AngZeTvJHk2Z7zkSQt0oKXhq6mqn4D3D5k/3lg35ztY8CxIeP+os/rS5L68y+LJalxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxhkCSGmcIJKlxvUKQ5IYkLyd5p7u//grj9iR5O8lUkkNDjn85SSXZ2Gc+kqTF6/uJ4BDwalXtAF7ttj8kyTrgaWAvsBO4P8nOOce3AXcC/9NzLpKkJegbgv3Ake7xEeDeIWN2A1NVdbaqLgIvdudd9nXgUaB6zkWStAR9Q3BTVV0A6O5vHDJmC3BuzvZ0t48k9wC/rKo3F3qhJAeTTCaZnJmZ6TltSdJl6xcakOQV4OYhhx4b8TUyZF8l+Xj3HHeN8iRVdRg4DDAYDPz0IEljsmAIquqOKx1L8m6SzVV1Iclm4L0hw6aBbXO2twLngU8B24E3k1ze/3qS3VX1q0WsQZLUQ99LQ0eBA93jA8D3hox5DdiRZHuSDcB9wNGqequqbqyqiaqaYDYYu4yAJF1bfUPwOHBnkneY/eXP4wBJbklyDKCqLgEPA8eBM8C3qup0z9eVJI3JgpeGrqaqfgPcPmT/eWDfnO1jwLEFnmuiz1wkSUvjXxZLUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1zhBIUuMMgSQ1LlW10nNYtCQzwC9Weh5LsBH49UpP4hpqbb3gmluxVtf8Z1W1af7ONRmCtSrJZFUNVnoe10pr6wXX3IqP2pq9NCRJjTMEktQ4Q3BtHV7pCVxjra0XXHMrPlJr9jsCSWqcnwgkqXGGQJIaZwjGKMkNSV5O8k53f/0Vxu1J8naSqSSHhhz/cpJKsnH5Z91P3zUneSLJT5KcSvLdJNdds8kv0gjvW5I81R0/lWTXqOeuVktdc5JtSX6Y5EyS00keufazX5o+73N3fF2SHyd56drNuqeq8jamG/A14FD3+BDw1SFj1gE/A/4c2AC8Ceycc3wbcJzZP5jbuNJrWu41A3cB67vHXx12/mq4LfS+dWP2Ad8HAtwG/GjUc1fjreeaNwO7usefBH76UV/znOP/CPwH8NJKr2fUm58Ixms/cKR7fAS4d8iY3cBUVZ2tqovAi915l30deBRYK9/i91pzVf2gqi51404AW5d3uku20PtGt/18zToBXJdk84jnrkZLXnNVXaiq1wGq6nfAGWDLtZz8EvV5n0myFfgc8I1rOem+DMF43VRVFwC6+xuHjNkCnJuzPd3tI8k9wC+r6s3lnugY9VrzPF9k9l9aq9Eoa7jSmFHXv9r0WfP/STIBfBr40finOHZ91/wks/+Q+/0yzW9ZrF/pCaw1SV4Bbh5y6LFRn2LIvkry8e457lrq3JbLcq153ms8BlwCXljc7K6ZBddwlTGjnLsa9Vnz7MHkE8C3gS9V1W/HOLflsuQ1J7kbeK+qTib57LgntpwMwSJV1R1XOpbk3csfi7uPiu8NGTbN7PcAl20FzgOfArYDbya5vP/1JLur6ldjW8ASLOOaLz/HAeBu4PbqLrKuQlddwwJjNoxw7mrUZ80k+RizEXihqr6zjPMcpz5r/nvgniT7gD8G/iTJN6vq88s43/FY6S8pPko34Ak+/MXp14aMWQ+cZfY/+pe/jPqrIeN+ztr4srjXmoE9wH8Dm1Z6LQusc8H3jdlrw3O/RPyvxbznq+3Wc80BngeeXOl1XKs1zxvzWdbQl8UrPoGP0g34U+BV4J3u/oZu/y3AsTnj9jH7K4qfAY9d4bnWSgh6rRmYYvZ66xvd7dmVXtNV1voHawAeAh7qHgd4ujv+FjBYzHu+Gm9LXTPwt8xeUjk1573dt9LrWe73ec5zrKkQ+L+YkKTG+ashSWqcIZCkxhkCSWqcIZCkxhkCSWqcIZCkxhkCSWrc/wLouA/ZRwywxQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_losses)),train_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:56.344036Z",
     "iopub.status.busy": "2021-02-23T20:06:56.341155Z",
     "iopub.status.idle": "2021-02-23T20:06:56.444453Z",
     "shell.execute_reply": "2021-02-23T20:06:56.444952Z"
    },
    "papermill": {
     "duration": 0.238569,
     "end_time": "2021-02-23T20:06:56.445107",
     "exception": false,
     "start_time": "2021-02-23T20:06:56.206538",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(test_losses)),test_losses)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:56.691969Z",
     "iopub.status.busy": "2021-02-23T20:06:56.690423Z",
     "iopub.status.idle": "2021-02-23T20:06:56.799793Z",
     "shell.execute_reply": "2021-02-23T20:06:56.800300Z"
    },
    "papermill": {
     "duration": 0.242026,
     "end_time": "2021-02-23T20:06:56.800464",
     "exception": false,
     "start_time": "2021-02-23T20:06:56.558438",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(train_acc)),train_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:57.054914Z",
     "iopub.status.busy": "2021-02-23T20:06:57.052131Z",
     "iopub.status.idle": "2021-02-23T20:06:57.156031Z",
     "shell.execute_reply": "2021-02-23T20:06:57.155104Z"
    },
    "papermill": {
     "duration": 0.233764,
     "end_time": "2021-02-23T20:06:57.156162",
     "exception": false,
     "start_time": "2021-02-23T20:06:56.922398",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(test_acc)),test_acc)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:57.396395Z",
     "iopub.status.busy": "2021-02-23T20:06:57.394491Z",
     "iopub.status.idle": "2021-02-23T20:06:57.397022Z",
     "shell.execute_reply": "2021-02-23T20:06:57.397499Z"
    },
    "papermill": {
     "duration": 0.119722,
     "end_time": "2021-02-23T20:06:57.397648",
     "exception": false,
     "start_time": "2021-02-23T20:06:57.277926",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# class TemporalModel(nn.Module) :\n",
    "#     def __init__(self, in_channels) :\n",
    "#         super(TemporalModel, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(\n",
    "#             in_channels = in_channels, \n",
    "#             out_channels = 96,\n",
    "#             kernel_size = 7,\n",
    "#             stride = 2\n",
    "#         )\n",
    "#         self.norm1 = nn.BatchNorm2d(96)\n",
    "#         self.conv2 = nn.Conv2d(\n",
    "#             in_channels = 96,\n",
    "#             out_channels = 256,\n",
    "#             kernel_size = 5,\n",
    "#             stride = 2\n",
    "#         )\n",
    "#         self.norm2 = nn.BatchNorm2d(256)\n",
    "#         self.conv3 = nn.Conv2d(\n",
    "#             in_channels = 256,\n",
    "#             out_channels = 512,\n",
    "#             kernel_size = 3,\n",
    "#             stride = 1\n",
    "#         )\n",
    "#         self.norm3 = nn.BatchNorm2d(512)\n",
    "#         self.conv4 = nn.Conv2d(\n",
    "#             in_channels = 512,\n",
    "#             out_channels = 512,\n",
    "#             kernel_size = 3,\n",
    "#             stride = 1\n",
    "#         )\n",
    "#         self.norm4 = nn.BatchNorm2d(512)\n",
    "#         self.conv5 = nn.Conv2d(\n",
    "#             in_channels = 512,\n",
    "#             out_channels = 512,\n",
    "#             kernel_size = 3,\n",
    "#             stride = 1\n",
    "#         )\n",
    "#         self.fc1 = nn.Linear(12800, 4096)\n",
    "#         self.fc2 = nn.Linear(4096, 2048)\n",
    "#         self.fc3 = nn.Linear(2048, 3)\n",
    "    \n",
    "#     def forward(self, x) :\n",
    "#         x = self.conv1(x)\n",
    "#         x = self.norm1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool2d(x,(2,2))\n",
    "#         x = self.conv2(x)\n",
    "#         x = self.norm2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool2d(x,(2,2))\n",
    "#         x = self.conv3(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv4(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = self.conv5(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.max_pool2d(x,(2,2))\n",
    "#         x = x.view(x.shape[0], -1)\n",
    "#         x = self.fc1(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.dropout(x, 0.2)\n",
    "#         x = self.fc2(x)\n",
    "#         x = F.relu(x)\n",
    "#         x = F.dropout(x, 0.2)\n",
    "#         x = self.fc3(x)\n",
    "#         x = F.softmax(x, dim=1)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:57.625851Z",
     "iopub.status.busy": "2021-02-23T20:06:57.623970Z",
     "iopub.status.idle": "2021-02-23T20:06:57.626511Z",
     "shell.execute_reply": "2021-02-23T20:06:57.626967Z"
    },
    "papermill": {
     "duration": 0.119045,
     "end_time": "2021-02-23T20:06:57.627111",
     "exception": false,
     "start_time": "2021-02-23T20:06:57.508066",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def train_2_stream(spatial, temporal, optim_spatial, optim_temporal, epochs=30) :\n",
    "#     '''\n",
    "    \n",
    "#     '''\n",
    "#     train_loss = []\n",
    "#     test_loss = []\n",
    "#     train_acc = []\n",
    "#     test_acc = []\n",
    "#     train_recall = []\n",
    "#     test_recall = []\n",
    "#     loss_func = nn.CrossEntropyLoss()\n",
    "    \n",
    "#     for e in range(epochs) :\n",
    "#         optim_spatial.zero_grad() \n",
    "#         optim_temporal.zero_grad()\n",
    "#         running_loss = [0.0, 0.0]\n",
    "#         for data in tqdm(trainloader) :\n",
    "#             frame, label, landmarks = data\n",
    "#             frame = frame.float()\n",
    "#             frame = frame.permute(0,3,1,2).to(device)\n",
    "#             label = label.long().to(device)\n",
    "#             optical_flow = generate_optical_flow(landmarks)\n",
    "#             optical_flow = torch.Tensor(optical_flow).to(device)\n",
    "            \n",
    "#             spatial_out = spatial(frame)\n",
    "#             spatial_out = F.softmax(spatial_out, dim=1)\n",
    "#             temporal_out = temporal(optical_flow)\n",
    "#             spatial_loss = loss_func(spatial_out, label)\n",
    "#             temporal_loss = loss_func(temporal_out, label)\n",
    "            \n",
    "#             spatial_loss.backward()\n",
    "#             temporal_loss.backward()\n",
    "#             optim_spatial.step()\n",
    "#             optim_temporal.step()\n",
    "            \n",
    "#             running_loss[0] += spatial_loss.item()\n",
    "#             running_loss[1] += temporal_loss.item()\n",
    "#         train_loss.append(running_loss)\n",
    "        \n",
    "#         running_loss = [0.0, 0.0]\n",
    "#         count = 0\n",
    "#         acc = [[], []]\n",
    "#         with torch.no_grad() :\n",
    "#             for data in tqdm(testloader) :\n",
    "#                 frame, label, landmarks = data\n",
    "#                 label = label.long().to(device)\n",
    "#                 frame = frame.float().to(device)\n",
    "#                 frame = frame.permute(0,3,1,2)\n",
    "#                 optical_flow = generate_optical_flow(landmarks)\n",
    "#                 optical_flow = torch.Tensor(optical_flow).to(device)\n",
    "\n",
    "#                 spatial_out = spatial(frame)\n",
    "#                 spatial_out = F.softmax(spatial_out, dim=1)\n",
    "#                 temporal_out = temporal(optical_flow)\n",
    "\n",
    "#                 spatial_loss = loss_func(spatial_out, label)\n",
    "#                 temporal_loss = loss_func(temporal_out, label)\n",
    "\n",
    "#                 running_loss[0] += spatial_loss.item()\n",
    "#                 running_loss[1] += temporal_loss.item()\n",
    "                \n",
    "#                 spatial_pred = spatial_out.argmax(axis=1)\n",
    "#                 temporal_pred = temporal_out.argmax(axis=1)\n",
    "#                 acc[0].append(torch.sum(spatial_pred == label)/len(label)) \n",
    "#                 acc[1].append(torch.sum(temporal_pred == label)/len(label))\n",
    "#         acc0 = torch.mean(torch.Tensor(acc[0]))\n",
    "#         acc1 = torch.mean(torch.Tensor(acc[1]))\n",
    "#         test_acc.append([acc0, acc1])\n",
    "#         test_loss.append(running_loss)\n",
    "#     return train_loss, test_acc, test_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:57.853819Z",
     "iopub.status.busy": "2021-02-23T20:06:57.851987Z",
     "iopub.status.idle": "2021-02-23T20:06:57.854507Z",
     "shell.execute_reply": "2021-02-23T20:06:57.854975Z"
    },
    "papermill": {
     "duration": 0.116604,
     "end_time": "2021-02-23T20:06:57.855118",
     "exception": false,
     "start_time": "2021-02-23T20:06:57.738514",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# temporal = TemporalModel(118)\n",
    "# adam_temporal = optim.Adam(temporal.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:58.080001Z",
     "iopub.status.busy": "2021-02-23T20:06:58.079391Z",
     "iopub.status.idle": "2021-02-23T20:06:58.083737Z",
     "shell.execute_reply": "2021-02-23T20:06:58.083266Z"
    },
    "papermill": {
     "duration": 0.118192,
     "end_time": "2021-02-23T20:06:58.083881",
     "exception": false,
     "start_time": "2021-02-23T20:06:57.965689",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# temporal = temporal.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:58.320724Z",
     "iopub.status.busy": "2021-02-23T20:06:58.318815Z",
     "iopub.status.idle": "2021-02-23T20:06:58.321382Z",
     "shell.execute_reply": "2021-02-23T20:06:58.321852Z"
    },
    "papermill": {
     "duration": 0.126406,
     "end_time": "2021-02-23T20:06:58.321997",
     "exception": false,
     "start_time": "2021-02-23T20:06:58.195591",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# train_loss, test_acc, test_loss = train_2_stream(spatial_model, temporal, adam_spatial, adam_temporal, epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:58.574231Z",
     "iopub.status.busy": "2021-02-23T20:06:58.564009Z",
     "iopub.status.idle": "2021-02-23T20:06:58.919889Z",
     "shell.execute_reply": "2021-02-23T20:06:58.919322Z"
    },
    "papermill": {
     "duration": 0.486216,
     "end_time": "2021-02-23T20:06:58.920025",
     "exception": false,
     "start_time": "2021-02-23T20:06:58.433809",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(temporal, './temporal.pt')\n",
    "torch.save(spatial_model , './spatial.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-23T20:06:59.150794Z",
     "iopub.status.busy": "2021-02-23T20:06:59.150116Z",
     "iopub.status.idle": "2021-02-23T20:06:59.154446Z",
     "shell.execute_reply": "2021-02-23T20:06:59.153921Z"
    },
    "papermill": {
     "duration": 0.12123,
     "end_time": "2021-02-23T20:06:59.154578",
     "exception": false,
     "start_time": "2021-02-23T20:06:59.033348",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# torch.save(torch.Tensor(train_loss), './trainloss.pt')\n",
    "# torch.save(torch.Tensor(test_loss), './testloss.pt')\n",
    "# torch.save(torch.Tensor(test_acc), './testacc.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 15492.355588,
   "end_time": "2021-02-23T20:07:01.586097",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-23T15:48:49.230509",
   "version": "2.2.2"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "095ddfa781044c28bbe2f0827f7f67f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_2fc8814a223c4d8ca7bf9f4bf12bde79",
       "max": 178728960.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_1739133a88444d7faf0badf0a9f2d9f7",
       "value": 178728960.0
      }
     },
     "133a2fefe2a34bedabaef59883d0104f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "15fc9cacefa048d0bc7256263aff7cec": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "1739133a88444d7faf0badf0a9f2d9f7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "1db5c18bbba34dce977bb4305ecfa7cb": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "2fc8814a223c4d8ca7bf9f4bf12bde79": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "37f3e6d3fbfa44c9b7bcb1018f67eef3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_bcf68add161f49d8b4319b1dd08c65a2",
        "IPY_MODEL_095ddfa781044c28bbe2f0827f7f67f3",
        "IPY_MODEL_99455fb07c494b55b2be340d0e6dd896"
       ],
       "layout": "IPY_MODEL_1db5c18bbba34dce977bb4305ecfa7cb"
      }
     },
     "99455fb07c494b55b2be340d0e6dd896": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_15fc9cacefa048d0bc7256263aff7cec",
       "placeholder": "​",
       "style": "IPY_MODEL_133a2fefe2a34bedabaef59883d0104f",
       "value": " 170M/170M [00:03&lt;00:00, 55.6MB/s]"
      }
     },
     "ba2801e1e4844f049f99529d81c99c33": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "bcf68add161f49d8b4319b1dd08c65a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_fbd04fce8d5343358de5d8558b123c20",
       "placeholder": "​",
       "style": "IPY_MODEL_ba2801e1e4844f049f99529d81c99c33",
       "value": "100%"
      }
     },
     "fbd04fce8d5343358de5d8558b123c20": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
